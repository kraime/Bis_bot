import openai
from typing import List, Dict, Any
import json
from loguru import logger
from config import (
    DEEPSEEK_API_KEY, LLM_CONFIG, SYSTEM_PROMPT,
    CONTEXT_PROMPT_TEMPLATE, SUMMARY_PROMPT_TEMPLATE
)


class DeepSeekService:
    def __init__(self):
        """Initialize DeepSeek service"""
        # Set OpenAI configuration for older version
        openai.api_key = DEEPSEEK_API_KEY
        openai.api_base = LLM_CONFIG["deepseek_base_url"]

    async def find_best_matches(self, user_profile: Dict[str, Any],
                                candidate_profiles: List[Dict[str, Any]],
                                top_k: int = None) -> List[Dict[str, Any]]:
        """Use DeepSeek to find best matching profiles"""

        if top_k is None:
            top_k = LLM_CONFIG["top_k"]

        # Prepare candidate profiles text
        candidates_text = "–ö–∞–Ω–¥–∏–¥–∞—Ç—ã –¥–ª—è —Å–æ–ø–æ—Å—Ç–∞–≤–ª–µ–Ω–∏—è:\n"
        for i, profile in enumerate(candidate_profiles):
            name = profile.get('first_name', '') or profile.get('username', f'–ü–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—å {i + 1}')
            candidates_text += f"""
            {i + 1}. {name}:
            - –°—Ñ–µ—Ä–∞ –¥–µ—è—Ç–µ–ª—å–Ω–æ—Å—Ç–∏: {profile['answer_1']}
            - –ß—Ç–æ –∏—â–µ—Ç –≤ —Å–æ–æ–±—â–µ—Å—Ç–≤–µ: {profile['answer_2']}
            - –ß–µ–º –º–æ–∂–µ—Ç –ø–æ–º–æ—á—å: {profile['answer_3']}
            """

        prompt = CONTEXT_PROMPT_TEMPLATE.format(
            user_answer_1=user_profile['answer_1'],
            user_answer_2=user_profile['answer_2'],
            user_answer_3=user_profile['answer_3'],
            candidates_text=candidates_text,
            top_k=min(top_k, len(candidate_profiles))
        )

        try:
            response = openai.ChatCompletion.create(
                model=LLM_CONFIG["deepseek_model"],
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=LLM_CONFIG["temperature"],
                max_tokens=LLM_CONFIG["max_tokens"]
            )

            result_text = response.choices[0].message['content'].strip()

            # Clean up JSON response - remove markdown code blocks
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            elif result_text.startswith('```'):
                result_text = result_text.replace('```', '').strip()

            # Clean up JSON response - remove markdown code blocks
            if result_text.startswith('```json'):
                result_text = result_text.replace('```json', '').replace('```', '').strip()
            elif result_text.startswith('```'):
                result_text = result_text.replace('```', '').strip()

            # Parse JSON response
            try:
                result = json.loads(result_text)
                matches = []

                for match in result.get('matches', []):
                    candidate_idx = match.get('candidate_index', 1) - 1  # Convert to 0-based index
                    if 0 <= candidate_idx < len(candidate_profiles):
                        profile = candidate_profiles[candidate_idx].copy()
                        profile['match_score'] = match.get('match_score', 0)
                        profile['match_reason'] = match.get('reason', '–ü–æ–¥—Ö–æ–¥—è—â–∏–π –∫–∞–Ω–¥–∏–¥–∞—Ç')
                        matches.append(profile)

                return matches[:top_k]

            except json.JSONDecodeError as e:
                logger.error(f"Failed to parse LLM response as JSON: {e}")
                logger.error(f"Response text: {result_text}")
                # Fallback: return first few candidates
                return candidate_profiles[:top_k]

        except Exception as e:
            logger.error(f"DeepSeek API error: {e}")
            # Fallback: return first few candidates
            return candidate_profiles[:top_k]

    async def generate_match_summary(self, user_profile: Dict[str, Any],
                                     matches: List[Dict[str, Any]]) -> str:
        """Generate a summary message for the matches"""

        matches_text = "–ù–∞–π–¥–µ–Ω–Ω—ã–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã:\n"
        for i, match in enumerate(matches):
            name = match.get('first_name', '') or match.get('username', f'–£—á–∞—Å—Ç–Ω–∏–∫ {i + 1}')
            matches_text += f"""
            {i + 1}. {name}:
            - –°—Ñ–µ—Ä–∞: {match['answer_1']}
            - –ò—â–µ—Ç: {match['answer_2']}
            - –ú–æ–∂–µ—Ç –ø–æ–º–æ—á—å: {match['answer_3']}
            - –ü—Ä–∏—á–∏–Ω–∞ —Å–æ–≤–ø–∞–¥–µ–Ω–∏—è: {match.get('match_reason', '–ü–æ–¥—Ö–æ–¥—è—â–∏–π –ø—Ä–æ—Ñ–∏–ª—å')}
            """

        prompt = SUMMARY_PROMPT_TEMPLATE.format(
            user_answer_1=user_profile['answer_1'],
            user_answer_2=user_profile['answer_2'],
            user_answer_3=user_profile['answer_3'],
            matches_text=matches_text
        )

        try:
            response = openai.ChatCompletion.create(
                model=LLM_CONFIG["deepseek_model"],
                messages=[
                    {"role": "system", "content": SYSTEM_PROMPT},
                    {"role": "user", "content": prompt}
                ],
                temperature=LLM_CONFIG["temperature"],
                max_tokens=300
            )

            return response.choices[0].message['content'].strip()

        except Exception as e:
            logger.error(f"Failed to generate match summary: {e}")
            return "–í–æ—Ç –ø–æ–¥—Ö–æ–¥—è—â–∏–µ –∫–æ–Ω—Ç–∞–∫—Ç—ã –¥–ª—è –∑–Ω–∞–∫–æ–º—Å—Ç–≤–∞! ü§ù"


# Global LLM service instance
llm_service = DeepSeekService()