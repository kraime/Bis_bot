#!/usr/bin/env python3
"""
Test script for chunking system and long profile matching
"""

import asyncio
import os
import sys
from dotenv import load_dotenv

# Add current directory to path
sys.path.insert(0, os.path.dirname(__file__))

# Load environment variables
load_dotenv()


async def test_chunking_system():
    """Test chunking system with long profiles"""
    print("üöÄ Testing Chunking System with Long Profiles\n")

    try:
        # Import modules
        from src.database import db
        from src.embeddings import embedding_service
        from src.vector_db import vector_db
        from src.text_processing import text_processor
        from src.llm_service import llm_service

        # Initialize systems
        print("üîç Initializing systems...")
        await db.connect()
        await vector_db.initialize()
        embedding_service.load_model()
        print("‚úÖ All systems initialized")

        # Clean existing test data
        print("\nüßπ Cleaning up existing test data...")
        try:
            import aiosqlite
            async with aiosqlite.connect(db.db_path) as conn:
                # Delete test profiles
                await conn.execute("""
                    DELETE FROM user_profiles WHERE user_id IN (
                        SELECT id FROM users WHERE telegram_id BETWEEN 20000 AND 29999
                    )
                """)
                await conn.execute("""
                    DELETE FROM profile_history WHERE user_id IN (
                        SELECT id FROM users WHERE telegram_id BETWEEN 20000 AND 29999
                    )
                """)
                await conn.execute("""
                    DELETE FROM user_states WHERE user_id IN (
                        SELECT id FROM users WHERE telegram_id BETWEEN 20000 AND 29999
                    )
                """)
                await conn.execute("DELETE FROM users WHERE telegram_id BETWEEN 20000 AND 29999")
                await conn.commit()

            # Clean Qdrant
            for user_id in range(1, 50):
                try:
                    vector_db.delete_profile(user_id)
                except:
                    pass

            print("‚úÖ Test data cleaned")
        except Exception as e:
            print(f"‚ö†Ô∏è Cleanup warning: {e}")

        # Create test profiles with long descriptions
        long_test_profiles = [
            {
                "telegram_id": 20001,
                "username": "ai_startup_founder",
                "first_name": "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä",
                "last_name": "–û—Å–Ω–æ–≤–∞—Ç–µ–ª—å",
                "birthday": "15.03.1985",
                "phone": "+79161234567",
                "answers": [
                    """–Ø –æ—Å–Ω–æ–≤–∞—Ç–µ–ª—å –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–π –¥–∏—Ä–µ–∫—Ç–æ—Ä AI-—Å—Ç–∞—Ä—Ç–∞–ø–∞, –∫–æ—Ç–æ—Ä—ã–π —Ä–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç —Ä–µ–≤–æ–ª—é—Ü–∏–æ–Ω–Ω—ã–µ —Ä–µ—à–µ–Ω–∏—è –≤ –æ–±–ª–∞—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ –±–∏–∑–Ω–µ—Å-–ø—Ä–æ—Ü–µ—Å—Å–æ–≤. –ù–∞—à–∞ –∫–æ–º–ø–∞–Ω–∏—è —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É–µ—Ç—Å—è –Ω–∞ —Å–æ–∑–¥–∞–Ω–∏–∏ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç—É–∞–ª—å–Ω—ã—Ö —Å–∏—Å—Ç–µ–º –æ–±—Ä–∞–±–æ—Ç–∫–∏ –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ —è–∑—ã–∫–∞, –∫–æ–º–ø—å—é—Ç–µ—Ä–Ω–æ–≥–æ –∑—Ä–µ–Ω–∏—è –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –ó–∞ –ø–æ—Å–ª–µ–¥–Ω–∏–µ 5 –ª–µ—Ç –º—ã –≤—ã—Ä–æ—Å–ª–∏ –æ—Ç –∫–æ–º–∞–Ω–¥—ã –∏–∑ 3 —á–µ–ª–æ–≤–µ–∫ –¥–æ 50+ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤, –ø—Ä–∏–≤–ª–µ–∫–ª–∏ $15M –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –∏ –∑–∞–ø—É—Å—Ç–∏–ª–∏ –ø—Ä–æ–¥—É–∫—Ç—ã, –∫–æ—Ç–æ—Ä—ã–º–∏ –ø–æ–ª—å–∑—É—é—Ç—Å—è –±–æ–ª–µ–µ 100,000 –∫–æ–º–ø–∞–Ω–∏–π –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É. –ú–æ–π –æ–ø—ã—Ç –≤–∫–ª—é—á–∞–µ—Ç 12 –ª–µ—Ç —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ –≤ –∫—Ä—É–ø–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏—è—Ö, –≤–∫–ª—é—á–∞—è Google –∏ –Ø–Ω–¥–µ–∫—Å, –≥–¥–µ —è —Ä—É–∫–æ–≤–æ–¥–∏–ª –∫–æ–º–∞–Ω–¥–∞–º–∏ –ø–æ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–µ ML-–∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤. –ò–º–µ—é PhD –≤ –æ–±–ª–∞—Å—Ç–∏ Computer Science, –æ–ø—É–±–ª–∏–∫–æ–≤–∞–ª –±–æ–ª–µ–µ 20 –Ω–∞—É—á–Ω—ã—Ö —Å—Ç–∞—Ç–µ–π –≤ —Ç–æ–ø–æ–≤—ã—Ö –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è—Ö –ø–æ –º–∞—à–∏–Ω–Ω–æ–º—É –æ–±—É—á–µ–Ω–∏—é. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ deep learning, NLP, computer vision, distributed systems –∏ high-performance computing. –ê–∫—Ç–∏–≤–Ω–æ —É—á–∞—Å—Ç–≤—É—é –≤ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–æ–º —Å–æ–æ–±—â–µ—Å—Ç–≤–µ, –≤—ã—Å—Ç—É–ø–∞—é –Ω–∞ –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è—Ö, –º–µ–Ω—Ç–æ—Ä—é —Å—Ç–∞—Ä—Ç–∞–ø—ã –≤ –∞–∫—Å–µ–ª–µ—Ä–∞—Ç–æ—Ä–∞—Ö. –ù–∞—à–∞ —Ç–µ–∫—É—â–∞—è –ø—Ä–æ–¥—É–∫—Ç–æ–≤–∞—è –ª–∏–Ω–µ–π–∫–∞ –≤–∫–ª—é—á–∞–µ—Ç –ø–ª–∞—Ç—Ñ–æ—Ä–º—É –¥–ª—è –∞–≤—Ç–æ–º–∞—Ç–∏–∑–∞—Ü–∏–∏ customer support —Å –ø–æ–º–æ—â—å—é AI-—á–∞—Ç–±–æ—Ç–æ–≤, —Å–∏—Å—Ç–µ–º—É –∞–Ω–∞–ª–∏–∑–∞ –¥–æ–∫—É–º–µ–Ω—Ç–æ–≤ –¥–ª—è —é—Ä–∏–¥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π, –∏ —Ä–µ—à–µ–Ω–∏–µ –¥–ª—è –ø—Ä–µ–¥–∏–∫—Ç–∏–≤–Ω–æ–π –∞–Ω–∞–ª–∏—Ç–∏–∫–∏ –≤ e-commerce.""",

                    """–ò—â—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏—Ö –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤ –∏ –∏–Ω–≤–µ—Å—Ç–æ—Ä–æ–≤ –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –Ω–∞—à–µ–≥–æ AI-—Å—Ç–∞—Ä—Ç–∞–ø–∞ –Ω–∞ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Ä—ã–Ω–∫–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –°–®–ê –∏ –ï–≤—Ä–æ–ø–µ. –ù–∞–º –Ω—É–∂–Ω—ã –ø–∞—Ä—Ç–Ω–µ—Ä—ã —Å —ç–∫—Å–ø–µ—Ä—Ç–∏–∑–æ–π –≤ enterprise sales, –∫–æ—Ç–æ—Ä—ã–µ –ø–æ–º–æ–≥—É—Ç –≤—ã–π—Ç–∏ –Ω–∞ –∫—Ä—É–ø–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ç–∏–≤–Ω—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤ –≤ —Ñ–∏–Ω—Ç–µ—Ö–µ, –∑–¥—Ä–∞–≤–æ–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∏ —Ä–∏—Ç–µ–π–ª–µ. –¢–∞–∫–∂–µ –∏—â—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏—Ö co-founder'–æ–≤ —Å –æ–ø—ã—Ç–æ–º –≤ –æ–±–ª–∞—Å—Ç–∏ MLOps, DevOps –∏ cloud infrastructure –¥–ª—è –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏ –Ω–∞—à–∏—Ö ML-–ø–∞–π–ø–ª–∞–π–Ω–æ–≤ –∏ —Å–Ω–∏–∂–µ–Ω–∏—è costs –Ω–∞ inference. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞ —Å —É–Ω–∏–≤–µ—Ä—Å–∏—Ç–µ—Ç–∞–º–∏ –∏ –∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å—Å–∫–∏–º–∏ —Ü–µ–Ω—Ç—Ä–∞–º–∏ –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω–æ–π —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–∏ cutting-edge –∞–ª–≥–æ—Ä–∏—Ç–º–æ–≤. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ M&A - –∫–∞–∫ –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω–∏–µ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö AI-–∫–æ–º–∞–Ω–¥, —Ç–∞–∫ –∏ –ø–æ—Ç–µ–Ω—Ü–∏–∞–ª—å–Ω—ã–π exit —á–µ—Ä–µ–∑ –ø—Ä–æ–¥–∞–∂—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–º—É –∏–Ω–≤–µ—Å—Ç–æ—Ä—É. –ù—É–∂–Ω—ã —ç–∫—Å–ø–µ—Ä—Ç—ã –ø–æ —Ä–µ–≥—É–ª–∏—Ä–æ–≤–∞–Ω–∏—é AI –≤ —Ä–∞–∑–Ω—ã—Ö —é—Ä–∏—Å–¥–∏–∫—Ü–∏—è—Ö, –æ—Å–æ–±–µ–Ω–Ω–æ —Å —É—á–µ—Ç–æ–º –Ω–æ–≤—ã—Ö –∑–∞–∫–æ–Ω–æ–≤ –æ AI –≤ –ï–°. –ò—â—É –º–µ–Ω—Ç–æ—Ä–∞ —Å –æ–ø—ã—Ç–æ–º scaling tech companies –æ—Ç $10M –¥–æ $100M+ ARR. –ò–Ω—Ç–µ—Ä–µ—Å–Ω—ã joint ventures —Å –∫—Ä—É–ø–Ω—ã–º–∏ –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏—è–º–∏ –¥–ª—è –≤–Ω–µ–¥—Ä–µ–Ω–∏—è –Ω–∞—à–∏—Ö AI-—Ä–µ—à–µ–Ω–∏–π –≤ –∏—Ö –ø—Ä–æ–¥—É–∫—Ç—ã. –¢–∞–∫–∂–µ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞ —Å cloud providers –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è compute credits –∏ —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–π –ø–æ–¥–¥–µ—Ä–∂–∫–∏.""",

                    """–ú–æ–≥—É –ø—Ä–µ–¥–æ—Å—Ç–∞–≤–∏—Ç—å –≥–ª—É–±–æ–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –≤ –æ–±–ª–∞—Å—Ç–∏ –∏—Å–∫—É—Å—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ –∏–Ω—Ç–µ–ª–ª–µ–∫—Ç–∞ –∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è, –≤–∫–ª—é—á–∞—è –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä—É –∏ —Ä–∞–∑—Ä–∞–±–æ—Ç–∫—É ML-—Å–∏—Å—Ç–µ–º –æ—Ç proof-of-concept –¥–æ production-ready —Ä–µ—à–µ–Ω–∏–π, —Å–ø–æ—Å–æ–±–Ω—ã—Ö –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å –º–∏–ª–ª–∏–æ–Ω—ã –∑–∞–ø—Ä–æ—Å–æ–≤ –≤ –¥–µ–Ω—å. –ü–æ–º–æ–≥—É —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º due diligence AI-—Å—Ç–∞—Ä—Ç–∞–ø–æ–≤, –æ—Ü–µ–Ω–∫–æ–π –∏—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏–π –∏ –∫–æ–º–∞–Ω–¥. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—é –¥–æ—Å—Ç—É–ø –∫ –Ω–∞—à–µ–π proprietary ML-–ø–ª–∞—Ç—Ñ–æ—Ä–º–µ –∏ –≥–æ—Ç–æ–≤—ã–º AI-–º–æ–¥–µ–ª—è–º —á–µ—Ä–µ–∑ API –¥–ª—è –±—ã—Å—Ç—Ä–æ–≥–æ –ø—Ä–æ—Ç–æ—Ç–∏–ø–∏—Ä–æ–≤–∞–Ω–∏—è. –ú–æ–≥—É —Å—Ç–∞—Ç—å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º advisor'–æ–º –∏–ª–∏ co-founder'–æ–º –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö AI-–ø—Ä–æ–µ–∫—Ç–∞—Ö. –ü–æ–¥–µ–ª—é—Å—å –æ–ø—ã—Ç–æ–º fundraising'–∞ - –æ—Ç seed –¥–æ Series B, –≤–∫–ª—é—á–∞—è –ø–æ–¥–≥–æ—Ç–æ–≤–∫—É pitch deck'–æ–≤, —Ä–∞–±–æ—Ç—É —Å VC –∏ angel investors. –ü–æ–º–æ–≥—É —Å hiring –∏ –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏–µ–º AI-–∫–æ–º–∞–Ω–¥, —É –º–µ–Ω—è –µ—Å—Ç—å –æ–±—à–∏—Ä–Ω–∞—è —Å–µ—Ç—å –∫–æ–Ω—Ç–∞–∫—Ç–æ–≤ —Å—Ä–µ–¥–∏ ML-–∏–Ω–∂–µ–Ω–µ—Ä–æ–≤, data scientists –∏ AI-–∏—Å—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª–µ–π. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—é –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ –ø–æ product management –¥–ª—è AI-–ø—Ä–æ–¥—É–∫—Ç–æ–≤, –≤–∫–ª—é—á–∞—è –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ product-market fit –∏ go-to-market —Å—Ç—Ä–∞—Ç–µ–≥–∏–∏. –ú–æ–≥—É –ø–æ–º–æ—á—å —Å —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–∏–º–∏ –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏—è–º–∏ –Ω–∞—à–∏—Ö AI-—Ä–µ—à–µ–Ω–∏–π –≤ —Å—É—â–µ—Å—Ç–≤—É—é—â–∏–µ –ø—Ä–æ–¥—É–∫—Ç—ã –ø–∞—Ä—Ç–Ω–µ—Ä–æ–≤. –ü–æ–¥–µ–ª—é—Å—å –∑–Ω–∞–Ω–∏—è–º–∏ –æ compliance –∏ —ç—Ç–∏—á–µ—Å–∫–∏—Ö –∞—Å–ø–µ–∫—Ç–∞—Ö AI, –æ—Å–æ–±–µ–Ω–Ω–æ –≤–∞–∂–Ω—ã–º–∏ –¥–ª—è enterprise –∫–ª–∏–µ–Ω—Ç–æ–≤. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—é –¥–æ—Å—Ç—É–ø –∫ –Ω–∞—à–µ–π customer base –¥–ª—è pilot –ø—Ä–æ–µ–∫—Ç–æ–≤ –∏ case studies."""
                ]
            },

            {
                "telegram_id": 20002,
                "username": "venture_capital_partner",
                "first_name": "–ú–∞—Ä–∏—è",
                "last_name": "–ò–Ω–≤–µ—Å—Ç–æ—Ä",
                "birthday": "22.07.1978",
                "phone": "+79167654321",
                "answers": [
                    """–Ø Managing Partner –≤ –æ–¥–Ω–æ–º –∏–∑ –≤–µ–¥—É—â–∏—Ö –≤–µ–Ω—á—É—Ä–Ω—ã—Ö —Ñ–æ–Ω–¥–æ–≤ –†–æ—Å—Å–∏–∏ —Å AUM $500M+, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–µ–º—Å—è –Ω–∞ –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏—è—Ö –≤ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å—Ç–∞—Ä—Ç–∞–ø—ã –Ω–∞ —Å—Ç–∞–¥–∏—è—Ö –æ—Ç seed –¥–æ Series B. –ó–∞ 15 –ª–µ—Ç –≤ –≤–µ–Ω—á—É—Ä–Ω–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏ —è –∏–Ω–≤–µ—Å—Ç–∏—Ä–æ–≤–∞–ª–∞ –≤ –±–æ–ª–µ–µ —á–µ–º 80 –∫–æ–º–ø–∞–Ω–∏–π, –∏–∑ –∫–æ—Ç–æ—Ä—ã—Ö 12 –¥–æ—Å—Ç–∏–≥–ª–∏ —Å—Ç–∞—Ç—É—Å–∞ unicorn, –∞ 25+ –±—ã–ª–∏ —É—Å–ø–µ—à–Ω–æ –ø—Ä–æ–¥–∞–Ω—ã —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–º –∏–Ω–≤–µ—Å—Ç–æ—Ä–∞–º –∏–ª–∏ –≤—ã—à–ª–∏ –Ω–∞ IPO. –ú–æ–π –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–æ–Ω–Ω—ã–π —Ñ–æ–∫—É—Å –≤–∫–ª—é—á–∞–µ—Ç fintech, healthtech, AI/ML, enterprise software, cybersecurity –∏ climate tech. –î–æ –≤–µ–Ω—á—É—Ä–Ω–æ–≥–æ –∫–∞–ø–∏—Ç–∞–ª–∞ —Ä–∞–±–æ—Ç–∞–ª–∞ –≤ Goldman Sachs –≤ –ø–æ–¥—Ä–∞–∑–¥–µ–ª–µ–Ω–∏–∏ tech M&A, –≥–¥–µ —É—á–∞—Å—Ç–≤–æ–≤–∞–ª–∞ –≤ —Å–¥–µ–ª–∫–∞—Ö –Ω–∞ –æ–±—â—É—é —Å—É–º–º—É –±–æ–ª–µ–µ $10B. –ò–º–µ—é MBA –æ—Ç Wharton –∏ —Å—Ç–µ–ø–µ–Ω—å –ø–æ –º–∞—Ç–µ–º–∞—Ç–∏–∫–µ –æ—Ç –ú–ì–£. –ê–∫—Ç–∏–≤–Ω–æ —É—á–∞—Å—Ç–≤—É—é –≤ —ç–∫–æ—Å–∏—Å—Ç–µ–º–µ —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤ –∫–∞–∫ board member –≤ 15+ –∫–æ–º–ø–∞–Ω–∏—è—Ö, –≥–¥–µ –ø–æ–º–æ–≥–∞—é —Å —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–º –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ–º, fundraising, M&A –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω–æ–π —ç–∫—Å–ø–∞–Ω—Å–∏–µ–π. –†–µ–≥—É–ª—è—Ä–Ω–æ –≤—ã—Å—Ç—É–ø–∞—é –Ω–∞ –≤–µ–¥—É—â–∏—Ö –∫–æ–Ω—Ñ–µ—Ä–µ–Ω—Ü–∏—è—Ö –ø–æ –≤–µ–Ω—á—É—Ä–Ω–æ–º—É –∫–∞–ø–∏—Ç–∞–ª—É, –≤–∫–ª—é—á–∞—è Slush, Web Summit, TechCrunch Disrupt. –Ø–≤–ª—è—é—Å—å LP –≤ –Ω–µ—Å–∫–æ–ª—å–∫–∏—Ö –∞–º–µ—Ä–∏–∫–∞–Ω—Å–∫–∏—Ö –∏ –µ–≤—Ä–æ–ø–µ–π—Å–∫–∏—Ö —Ñ–æ–Ω–¥–∞—Ö, —á—Ç–æ –¥–∞–µ—Ç –º–Ω–µ –≥–ª–æ–±–∞–ª—å–Ω—É—é –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤—É –Ω–∞ —Ä—ã–Ω–æ–∫. –í–µ–¥—É —Å–æ–±—Å—Ç–≤–µ–Ω–Ω—ã–π angel portfolio –∏–∑ 30+ early-stage –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã.""",

                    """–ê–∫—Ç–∏–≤–Ω–æ –∏—â—É breakthrough —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ —Å—Ç–∞—Ä—Ç–∞–ø—ã –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –æ—Ç $1M –¥–æ $50M, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –æ–±–ª–∞—Å—Ç–∏ artificial intelligence, quantum computing, biotechnology –∏ clean energy. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –∫–æ–º–ø–∞–Ω–∏–∏ —Å strong technical moats, experienced founding teams –∏ clear path to $100M+ revenue. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –∫–∞–∫ —Ä–æ—Å—Å–∏–π—Å–∫–∏–µ, —Ç–∞–∫ –∏ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è co-investment —Å —Ç–æ–ø–æ–≤—ã–º–∏ –∑–∞—Ä—É–±–µ–∂–Ω—ã–º–∏ —Ñ–æ–Ω–¥–∞–º–∏. –ò—â—É —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–∏–µ –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–∞ —Å corporate venture arms –∫—Ä—É–ø–Ω—ã—Ö —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏—Ö –∫–æ–º–ø–∞–Ω–∏–π –¥–ª—è —Å–æ–≤–º–µ—Å—Ç–Ω—ã—Ö –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π –∏ –æ–±–µ—Å–ø–µ—á–µ–Ω–∏—è portfolio companies –¥–æ—Å—Ç—É–ø–æ–º –∫ enterprise –∫–ª–∏–µ–Ω—Ç–∞–º. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ lead –∏–ª–∏ co-lead –∫—Ä—É–ø–Ω—ã—Ö —Ä–∞—É–Ω–¥–æ–≤ Series A/B –≤ –∫–æ–º–ø–∞–Ω–∏—è—Ö —Å proven product-market fit –∏ strong unit economics. –ê–∫—Ç–∏–≤–Ω–æ —Ä–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é cross-border —Å–¥–µ–ª–∫–∏, –æ—Å–æ–±–µ–Ω–Ω–æ –¥–ª—è –ø–æ–º–æ—â–∏ —Ä–æ—Å—Å–∏–π—Å–∫–∏–º —Å—Ç–∞—Ä—Ç–∞–ø–∞–º –≤ –≤—ã—Ö–æ–¥–µ –Ω–∞ –º–µ–∂–¥—É–Ω–∞—Ä–æ–¥–Ω—ã–µ —Ä—ã–Ω–∫–∏ —á–µ—Ä–µ–∑ –Ω–∞—à–∏ –ø–∞—Ä—Ç–Ω–µ—Ä—Å–∫–∏–µ —Ñ–æ–Ω–¥—ã –≤ –°–®–ê, –ï–≤—Ä–æ–ø–µ –∏ –ê–∑–∏–∏. –ò—â—É experienced entrepreneurs in residence –¥–ª—è —Ä–∞–±–æ—Ç—ã —Å –Ω–∞—à–∏–º–∏ portfolio companies –≤ –∫–∞—á–µ—Å—Ç–≤–µ interim executives –∏–ª–∏ advisors. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç partnership opportunities —Å leading accelerators –∏ incubators –¥–ª—è early-stage deal flow. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω–∏—è sector-specific funds, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ –æ–±–ª–∞—Å—Ç–∏ climate tech –∏ healthcare innovation.""",

                    """–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é comprehensive support –¥–ª—è portfolio companies –Ω–∞ –≤—Å–µ—Ö —Å—Ç–∞–¥–∏—è—Ö –∏—Ö —Ä–∞–∑–≤–∏—Ç–∏—è, –≤–∫–ª—é—á–∞—è —Å—Ç—Ä–∞—Ç–µ–≥–∏—á–µ—Å–∫–æ–µ –ø–ª–∞–Ω–∏—Ä–æ–≤–∞–Ω–∏–µ, product development guidance, go-to-market strategy –∏ international expansion. –ü–æ–º–æ–≥–∞—é —Å –ø–æ—Å–ª–µ–¥—É—é—â–∏–º–∏ —Ä–∞—É–Ω–¥–∞–º–∏ fundraising —á–µ—Ä–µ–∑ –º–æ—é extensive network –∏–∑ 200+ institutional investors –ø–æ –≤—Å–µ–º—É –º–∏—Ä—É. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é –¥–æ—Å—Ç—É–ø –∫ top-tier executive talent —á–µ—Ä–µ–∑ partnership —Å leading executive search firms –∏ –º–æ—é personal network –∏–∑ successful entrepreneurs –∏ C-level executives. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é business development support —á–µ—Ä–µ–∑ connections —Å potential enterprise customers, strategic partners –∏ distribution channels. –ü–æ–º–æ–≥–∞—é —Å M&A opportunities –∫–∞–∫ –Ω–∞ buy-side, —Ç–∞–∫ –∏ –Ω–∞ sell-side, leveraging –º–æ–π –æ–ø—ã—Ç –≤ investment banking –∏ extensive network —Å—Ä–µ–¥–∏ strategic acquirers. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é operational expertise –≤ areas –≤–∫–ª—é—á–∞—è financial planning, legal structuring, HR policies –∏ corporate governance. –ü–æ–º–æ–≥–∞—é —Å international market entry —á–µ—Ä–µ–∑ partnerships —Å local funds –∏ advisors –≤ key markets. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é PR –∏ marketing support —á–µ—Ä–µ–∑ connections —Å leading tech media –∏ analyst firms. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é access –∫ exclusive industry events, conferences –∏ networking opportunities. –ü–æ–º–æ–≥–∞—é —Å talent acquisition —á–µ—Ä–µ–∑ –º–æ—é network –∏ partnerships —Å technical recruiting firms. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é ongoing mentorship –∏ strategic advice based –Ω–∞ –º–æ–π experience building –∏ scaling technology companies."""
                ]
            },

            {
                "telegram_id": 20003,
                "username": "enterprise_sales_director",
                "first_name": "–î–º–∏—Ç—Ä–∏–π",
                "last_name": "–ü—Ä–æ–¥–∞–∂–∏",
                "birthday": "10.11.1982",
                "phone": "+79169876543",
                "answers": [
                    """–Ø Global Sales Director —Å 18-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è enterprise sales –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–π –≤ B2B SaaS –∫–æ–º–ø–∞–Ω–∏—è—Ö –æ—Ç early-stage —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤ –¥–æ –ø—É–±–ª–∏—á–Ω—ã—Ö –∫–æ—Ä–ø–æ—Ä–∞—Ü–∏–π —Å revenue $1B+. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ complex enterprise deals —Ä–∞–∑–º–µ—Ä–æ–º –æ—Ç $100K –¥–æ $10M+ —Å sales cycles –æ—Ç 6 –¥–æ 24 –º–µ—Å—è—Ü–µ–≤. –ó–∞ —Å–≤–æ—é –∫–∞—Ä—å–µ—Ä—É –ø–æ—Å—Ç—Ä–æ–∏–ª sales teams –≤ 4 –∫–æ–º–ø–∞–Ω–∏—è—Ö, –∫–æ—Ç–æ—Ä—ã–µ –¥–æ—Å—Ç–∏–≥–ª–∏ successful exits —á–µ—Ä–µ–∑ IPO –∏–ª–∏ acquisition. –ú–æ–π track record –≤–∫–ª—é—á–∞–µ—Ç —Ä–æ—Å—Ç revenue –æ—Ç $2M –¥–æ $200M ARR –≤ —Ä–æ–ª–∏ VP Sales –≤ fintech —Å—Ç–∞—Ä—Ç–∞–ø–µ, –∫–æ—Ç–æ—Ä—ã–π –±—ã–ª –ø—Ä–∏–æ–±—Ä–µ—Ç–µ–Ω –∑–∞ $1.2B. –ò–º–µ—é –≥–ª—É–±–æ–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –≤ vertical markets –≤–∫–ª—é—á–∞—è financial services, healthcare, manufacturing, retail –∏ government. –†–∞–∑–≤–∏–ª comprehensive sales methodology, –∫–æ—Ç–æ—Ä–∞—è —É–≤–µ–ª–∏—á–∏–≤–∞–µ—Ç win rates –Ω–∞ 40% –∏ —Å–æ–∫—Ä–∞—â–∞–µ—Ç sales cycles –Ω–∞ 25%. –ü–æ—Å—Ç—Ä–æ–∏–ª –∏ —É–ø—Ä–∞–≤–ª—è–ª international sales teams –≤ 15+ —Å—Ç—Ä–∞–Ω–∞—Ö, –≤–∫–ª—é—á–∞—è –°–®–ê, –ï–≤—Ä–æ–ø—É, APAC –∏ LATAM. –ò–º–µ—é extensive network –∏–∑ 500+ enterprise decision makers –≤ Fortune 500 –∫–æ–º–ø–∞–Ω–∏—è—Ö. –†–µ–≥—É–ª—è—Ä–Ω–æ –≤—ã—Å—Ç—É–ø–∞—é –Ω–∞ leading sales conferences –∏ —è–≤–ª—è—é—Å—å advisor –¥–ª—è 10+ B2B —Å—Ç–∞—Ä—Ç–∞–ø–æ–≤. –°–µ—Ä—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω –ø–æ major sales methodologies –≤–∫–ª—é—á–∞—è MEDDIC, Challenger Sale, –∏ Solution Selling. –ò–º–µ—é MBA –≤ –æ–±–ª–∞—Å—Ç–∏ International Business –∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏–∑—É—á–∞—é emerging trends –≤ enterprise software –∏ digital transformation.""",

                    """–ò—â—É –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ –ø—Ä–∏—Å–æ–µ–¥–∏–Ω–∏—Ç—å—Å—è –∫ high-growth B2B SaaS —Å—Ç–∞—Ä—Ç–∞–ø–∞–º –≤ –∫–∞—á–µ—Å—Ç–≤–µ Chief Revenue Officer, VP Sales –∏–ª–∏ co-founder —Å equity participation –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è –∏—Ö enterprise sales operations. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç –∫–æ–º–ø–∞–Ω–∏–∏ —Å proven product-market fit, strong technical team –∏ –≥–æ—Ç–æ–≤–Ω–æ—Å—Ç—å—é –∫ aggressive international expansion. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –∫–∞–∫ full-time executive roles, —Ç–∞–∫ –∏ advisory positions —Å equity compensation –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã—Ö —Å—Ç–∞—Ä—Ç–∞–ø–∞—Ö –Ω–∞ —Å—Ç–∞–¥–∏–∏ Series A-C. –ò—â—É partnerships —Å venture capital funds –¥–ª—è due diligence –∏—Ö portfolio companies –∏ –ø–æ–º–æ—â–∏ –≤ scaling sales operations. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç consulting opportunities –¥–ª—è –ø–æ–º–æ—â–∏ enterprise software companies –≤ entering new vertical markets –∏–ª–∏ geographic regions. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é –≤–æ–∑–º–æ–∂–Ω–æ—Å—Ç–∏ —Å–æ–∑–¥–∞–Ω–∏—è —Å–æ–±—Å—Ç–≤–µ–Ω–Ω–æ–≥–æ sales consulting firm, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–µ–≥–æ—Å—è –Ω–∞ B2B SaaS companies. –ò—â—É strategic partnerships —Å leading sales technology vendors –¥–ª—è joint go-to-market initiatives. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç board positions –≤ technology companies, –≥–¥–µ –º–æ–≥—É –ø—Ä–∏–º–µ–Ω–∏—Ç—å –º–æ–π operational expertise. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é opportunities –¥–ª—è angel investing –≤ early-stage B2B startups, –æ—Å–æ–±–µ–Ω–Ω–æ –≥–¥–µ –º–æ–≥—É –¥–æ–±–∞–≤–∏—Ç—å significant value —á–µ—Ä–µ–∑ –º–æ–π sales expertise –∏ network. –ò—â—É partnerships —Å executive search firms, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏—Ö—Å—è –Ω–∞ sales leadership roles. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç speaking opportunities –Ω–∞ major industry conferences –∏ participation –≤ thought leadership initiatives.""",

                    """–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é comprehensive sales leadership –∏ operational expertise –¥–ª—è scaling enterprise sales organizations –æ—Ç zero to $100M+ ARR. –ü–æ–º–æ–≥–∞—é —Å hiring –∏ onboarding world-class sales talent, –≤–∫–ª—é—á–∞—è account executives, sales engineers, customer success managers –∏ sales development representatives. –†–∞–∑—Ä–∞–±–∞—Ç—ã–≤–∞—é –∏ implement proven sales processes, methodologies –∏ playbooks, –∫–æ—Ç–æ—Ä—ã–µ –æ–±–µ—Å–ø–µ—á–∏–≤–∞—é—Ç predictable revenue growth –∏ high team performance. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é extensive network –∏–∑ enterprise decision makers –¥–ª—è warm introductions –∏ pilot opportunities. –ü–æ–º–æ–≥–∞—é —Å go-to-market strategy development, –≤–∫–ª—é—á–∞—è market segmentation, competitive positioning –∏ pricing strategy. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é sales training –∏ coaching programs –¥–ª—è improvement team performance –∏ individual quota attainment. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é expertise –≤ sales technology stack optimization, –≤–∫–ª—é—á–∞—è CRM implementation, sales automation –∏ analytics tools. –ü–æ–º–æ–≥–∞—é —Å international expansion strategy –∏ establishing sales operations –≤ new geographic markets. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é customer advisory services –¥–ª—è product development prioritization based –Ω–∞ enterprise customer feedback. –ü–æ–º–æ–≥–∞—é —Å partnership development –∏ channel sales strategies –¥–ª—è accelerated market penetration. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é ongoing strategic advice –∏ mentorship –¥–ª—è sales leadership teams. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é access –∫ industry best practices –∏ benchmarking data –¥–ª—è continuous improvement initiatives."""
                ]
            },

            {
                "telegram_id": 20004,
                "username": "fintech_product_manager",
                "first_name": "–ê–Ω–Ω–∞",
                "last_name": "–ü—Ä–æ–¥—É–∫—Ç",
                "birthday": "05.09.1987",
                "phone": "+79162345678",
                "answers": [
                    """–Ø Senior Product Manager –≤ leading fintech company —Å 10-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º —Å–æ–∑–¥–∞–Ω–∏—è –∏ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è financial products, –∫–æ—Ç–æ—Ä—ã–º–∏ –ø–æ–ª—å–∑—É—é—Ç—Å—è –º–∏–ª–ª–∏–æ–Ω—ã –∫–ª–∏–µ–Ω—Ç–æ–≤ –µ–∂–µ–¥–Ω–µ–≤–Ω–æ. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ payments, lending, wealth management –∏ regulatory compliance –≤ –≤—ã—Å–æ–∫–æ —Ä–µ–≥—É–ª–∏—Ä—É–µ–º–æ–π —Ñ–∏–Ω–∞–Ω—Å–æ–≤–æ–π –∏–Ω–¥—É—Å—Ç—Ä–∏–∏. –ó–∞ –º–æ—é –∫–∞—Ä—å–µ—Ä—É —è –∑–∞–ø—É—Å—Ç–∏–ª–∞ 15+ successful products, –≤–∫–ª—é—á–∞—è mobile payment platform —Å $2B+ annual transaction volume, AI-powered credit scoring system –∏ robo-advisor platform —Å $500M+ assets under management. –ò–º–µ—é –≥–ª—É–±–æ–∫—É—é —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –≤ user experience design –¥–ª—è financial services, data-driven product development –∏ A/B testing methodologies. –†–∞–±–æ—Ç–∞–ª–∞ –≤ —Ä–∞–∑–ª–∏—á–Ω—ã—Ö —Ñ–∏–Ω—Ç–µ—Ö —Å–µ–≥–º–µ–Ω—Ç–∞—Ö –æ—Ç consumer banking –¥–æ institutional trading platforms. –ò–º–µ—é strong technical background —Å –ø–æ–Ω–∏–º–∞–Ω–∏–µ–º blockchain technology, machine learning applications –≤ finance –∏ cybersecurity requirements. –ê–∫—Ç–∏–≤–Ω–æ —É—á–∞—Å—Ç–≤—É—é –≤ fintech community –∫–∞–∫ speaker –Ω–∞ major conferences –≤–∫–ª—é—á–∞—è Money20/20, Finovate –∏ LendIt. –Ø–≤–ª—è—é—Å—å advisor –¥–ª—è 5+ fintech startups –∏ mentor –≤ leading accelerator programs. –ò–º–µ—é MBA –≤ Finance –∏ –ø–æ—Å—Ç–æ—è–Ω–Ω–æ –∏–∑—É—á–∞—é emerging trends –≤–∫–ª—é—á–∞—è DeFi, central bank digital currencies –∏ embedded finance. –°–µ—Ä—Ç–∏—Ñ–∏—Ü–∏—Ä–æ–≤–∞–Ω–∞ –ø–æ product management methodologies –≤–∫–ª—é—á–∞—è Agile, Lean Startup –∏ Design Thinking. –ü–æ–¥–¥–µ—Ä–∂–∏–≤–∞—é extensive network relationships —Å regulators, financial institutions –∏ fintech ecosystem players.""",

                    """–ê–∫—Ç–∏–≤–Ω–æ –∏—â—É opportunities –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è revolutionary fintech products, –∫–æ—Ç–æ—Ä—ã–µ democratize access –∫ financial services –∏ improve financial inclusion globally. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç partnerships —Å traditional financial institutions –¥–ª—è digital transformation initiatives –∏ creation of innovative customer experiences. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é co-founder opportunities –≤ early-stage fintech startups, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ areas –≤–∫–ª—é—á–∞—è embedded finance, SME lending, cross-border payments –∏ sustainable finance. –ò—â—É collaboration —Å AI/ML teams –¥–ª—è development of next-generation financial products powered by artificial intelligence –∏ predictive analytics. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç consulting opportunities –¥–ª—è helping established financial services companies —Å product strategy, digital transformation –∏ regulatory compliance. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é advisory roles –≤ fintech startups –≥–¥–µ –º–æ–≥—É leverage –º–æ–π product expertise –∏ industry connections. –ò—â—É partnerships —Å regulatory bodies –∏ policy makers –¥–ª—è shaping future of financial services regulation –∏ promoting innovation-friendly policies. –ò–Ω—Ç–µ—Ä–µ—Å—É—é—Ç opportunities –¥–ª—è expanding –≤ emerging markets, –æ—Å–æ–±–µ–Ω–Ω–æ –≤ regions —Å underserved populations –∏ significant financial inclusion gaps. –†–∞—Å—Å–º–∞—Ç—Ä–∏–≤–∞—é roles –≤ venture capital funds, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—â–∏—Ö—Å—è –Ω–∞ fintech investments, –≥–¥–µ –º–æ–≥—É provide product due diligence –∏ portfolio company support. –ò—â—É speaking opportunities –∏ thought leadership platforms –¥–ª—è sharing insights –æ future of financial services –∏ product innovation trends.""",

                    """–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é comprehensive product management expertise –¥–ª—è fintech companies –Ω–∞ –≤—Å–µ—Ö stages of development, –æ—Ç concept validation –¥–æ scale –∏ international expansion. –ü–æ–º–æ–≥–∞—é —Å product strategy development, roadmap planning –∏ prioritization based –Ω–∞ market research, customer feedback –∏ competitive analysis. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é deep understanding regulatory requirements across multiple jurisdictions –∏ guidance –Ω–∞ compliance-first product development. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é extensive network –∏–∑ financial services executives, regulators, technology vendors –∏ industry experts –¥–ª—è partnerships –∏ business development. –ü–æ–º–æ–≥–∞—é —Å user experience design –∏ customer journey optimization specifically –¥–ª—è financial products —Å focus –Ω–∞ trust, security –∏ ease of use. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é data analytics expertise –¥–ª—è product performance measurement, customer behavior analysis –∏ predictive modeling. –ü–æ–º–æ–≥–∞—é —Å go-to-market strategy development, –≤–∫–ª—é—á–∞—è pricing models, distribution channels –∏ customer acquisition strategies. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é guidance –Ω–∞ technology architecture decisions, vendor selection –∏ integration strategies –¥–ª—è financial services infrastructure. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é fundraising support —á–µ—Ä–µ–∑ connections —Å fintech-focused investors –∏ assistance —Å product positioning –¥–ª—è investment presentations. –ü–æ–º–æ–≥–∞—é —Å international expansion strategy, –≤–∫–ª—é—á–∞—è market entry planning, local partnership development –∏ regulatory navigation. –û–±–µ—Å–ø–µ—á–∏–≤–∞—é ongoing product coaching –∏ mentorship –¥–ª—è product teams –∏ leadership. –ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é access –∫ industry benchmarking data, best practices –∏ emerging trend analysis –¥–ª—è competitive advantage."""
                ]
            }
        ]

        created_users = []

        print(f"\nüë• Creating {len(long_test_profiles)} long test profiles...")

        for i, profile_data in enumerate(long_test_profiles, 1):
            try:
                print(f"\nüîç Creating profile {i}/{len(long_test_profiles)}: {profile_data['first_name']}")

                # Create user
                user = await db.get_or_create_user(
                    telegram_id=profile_data["telegram_id"],
                    username=profile_data["username"],
                    first_name=profile_data["first_name"],
                    last_name=profile_data["last_name"]
                )

                # Update phone and birthday
                await db.update_user_phone(user['id'], profile_data["phone"])
                await db.update_user_birthday(user['id'], profile_data["birthday"])

                # Process profile text and test chunking
                processed_data = text_processor.prepare_profile_text(
                    profile_data["answers"][0],
                    profile_data["answers"][1],
                    profile_data["answers"][2]
                )

                print(f"  üìä Text stats:")
                print(f"    Total length: {processed_data['total_length']} chars")
                print(f"    Chunks created: {len(processed_data['chunks'])}")
                print(f"    Keywords: {processed_data['keywords'][:8]}...")

                # Show chunk details
                for j, chunk in enumerate(processed_data['chunks'], 1):
                    print(f"    Chunk {j}: {len(chunk)} chars - {chunk[:60]}...")

                # Create embedding (will handle chunking automatically)
                embedding = embedding_service.create_profile_embedding(
                    processed_data['clean_answers']['answer_1'],
                    processed_data['clean_answers']['answer_2'],
                    processed_data['clean_answers']['answer_3']
                )

                print(f"  üß† Embedding dimension: {len(embedding)}")

                # Save to SQLite
                await db.save_user_profile(
                    user['id'],
                    processed_data['clean_answers']['answer_1'],
                    processed_data['clean_answers']['answer_2'],
                    processed_data['clean_answers']['answer_3'],
                    embedding,
                    processed_data['keywords']
                )

                # Save to Qdrant
                profile_payload = {
                    "telegram_id": user['telegram_id'],
                    "username": user['username'],
                    "first_name": user['first_name'],
                    "last_name": user['last_name'],
                    "answer_1": processed_data['clean_answers']['answer_1'],
                    "answer_2": processed_data['clean_answers']['answer_2'],
                    "answer_3": processed_data['clean_answers']['answer_3'],
                    "keywords": processed_data['keywords']
                }

                vector_db.save_profile_embedding(user['id'], embedding, profile_payload)

                created_users.append({
                    'user': user,
                    'profile_data': profile_data,
                    'processed_data': processed_data,
                    'embedding': embedding
                })

                print(f"  ‚úÖ Profile created and saved")

            except Exception as e:
                print(f"  ‚ùå Failed to create profile for {profile_data['first_name']}: {e}")
                import traceback
                traceback.print_exc()

        print(f"\n‚úÖ Created {len(created_users)} long profiles successfully")

        # Test matching between profiles
        print(f"\nüîç Testing matching between long profiles...")

        for i, user_data in enumerate(created_users, 1):
            user = user_data['user']
            profile_data = user_data['profile_data']

            print(f"\n--- Matching Test {i}/{len(created_users)}: {profile_data['first_name']} ---")
            print(f"üë§ Profile summary:")
            print(f"   üè¢ Field: {profile_data['answers'][0][:100]}...")
            print(f"   üîç Looking for: {profile_data['answers'][1][:100]}...")
            print(f"   ü§ù Can help: {profile_data['answers'][2][:100]}...")
            print(f"   üìä Text length: {user_data['processed_data']['total_length']} chars")
            print(f"   üß© Chunks: {len(user_data['processed_data']['chunks'])}")

            try:
                # Get user profile from database
                db_profile = await db.get_user_profile(user['id'])
                if not db_profile:
                    print("  ‚ùå Profile not found in database")
                    continue

                # Test keyword-based search
                keywords = db_profile.get('keywords', [])
                if keywords:
                    keyword_profiles = await db.find_profiles_with_keywords(
                        user['id'], keywords, limit=10
                    )
                    print(f"  üîç Keyword search: found {len(keyword_profiles)} profiles")
                    for kp in keyword_profiles:
                        print(f"    - {kp['first_name']}: {kp['answer_1'][:50]}...")
                else:
                    keyword_profiles = []

                # Test vector search
                vector_profiles = vector_db.search_similar_profiles(
                    user_data['embedding'], user['id'], limit=10
                )
                print(f"  üîç Vector search: found {len(vector_profiles)} profiles")
                for vp in vector_profiles:
                    similarity = vp.get('similarity_score', 0)
                    print(f"    - {vp['first_name']} (similarity: {similarity:.3f}): {vp['answer_1'][:50]}...")

                # Combine results
                all_candidates = []
                seen_users = set()

                for profiles_list in [keyword_profiles, vector_profiles]:
                    for p in profiles_list:
                        user_key = p['telegram_id']
                        if user_key not in seen_users:
                            seen_users.add(user_key)
                            all_candidates.append(p)

                print(f"  üìä Total candidates: {len(all_candidates)}")

                if all_candidates:
                    # Test LLM matching
                    try:
                        best_matches = await llm_service.find_best_matches(
                            db_profile, all_candidates, top_k=3
                        )
                        print(f"  ü§ñ LLM analysis: {len(best_matches)} best matches")

                        for j, match in enumerate(best_matches, 1):
                            name = match.get('first_name', 'Unknown')
                            score = match.get('match_score', 'N/A')
                            reason = match.get('match_reason', 'No reason')
                            print(f"    {j}. {name} (Score: {score})")
                            print(f"       Reason: {reason}")
                            print(f"       Field: {match.get('answer_1', '')[:80]}...")

                        # Test summary generation
                        if best_matches:
                            summary = await llm_service.generate_match_summary(db_profile, best_matches)
                            print(f"  üìù Summary: {summary[:120]}...")

                    except Exception as e:
                        print(f"  ‚ö†Ô∏è LLM matching failed: {e}")
                        import traceback
                        traceback.print_exc()
                else:
                    print("  ‚ö†Ô∏è No candidates found for matching")

            except Exception as e:
                print(f"  ‚ùå Matching failed: {e}")
                import traceback
                traceback.print_exc()

        # Test specific matching scenarios
        print(f"\nüéØ Testing specific cross-matching scenarios...")

        # AI Founder looking for Investor
        ai_founder = next((u for u in created_users if 'ai_startup_founder' in u['user']['username']), None)
        vc_partner = next((u for u in created_users if 'venture_capital_partner' in u['user']['username']), None)

        if ai_founder and vc_partner:
            print(f"\nüìã Scenario 1: AI Founder ‚Üí VC Partner matching")
            ai_profile = await db.get_user_profile(ai_founder['user']['id'])

            # Search for investor
            vector_results = vector_db.search_similar_profiles(
                ai_founder['embedding'], ai_founder['user']['id'], limit=5
            )

            investor_found = any(p['telegram_id'] == vc_partner['user']['telegram_id'] for p in vector_results)
            print(f"  {'‚úÖ' if investor_found else '‚ùå'} VC Partner found in vector search: {investor_found}")

            if vector_results:
                llm_matches = await llm_service.find_best_matches(ai_profile, vector_results, top_k=3)
                investor_in_top = any(m['telegram_id'] == vc_partner['user']['telegram_id'] for m in llm_matches)
                print(f"  {'‚úÖ' if investor_in_top else '‚ùå'} VC Partner in LLM top matches: {investor_in_top}")

                if investor_in_top:
                    match = next(m for m in llm_matches if m['telegram_id'] == vc_partner['user']['telegram_id'])
                    print(f"  üéØ Match score: {match.get('match_score', 'N/A')}")
                    print(f"  üí° Reason: {match.get('match_reason', 'No reason')}")

        # VC Partner looking for AI Founder
        if vc_partner and ai_founder:
            print(f"\nüìã Scenario 2: VC Partner ‚Üí AI Founder matching")
            vc_profile = await db.get_user_profile(vc_partner['user']['id'])

            vector_results = vector_db.search_similar_profiles(
                vc_partner['embedding'], vc_partner['user']['id'], limit=5
            )

            founder_found = any(p['telegram_id'] == ai_founder['user']['telegram_id'] for p in vector_results)
            print(f"  {'‚úÖ' if founder_found else '‚ùå'} AI Founder found in vector search: {founder_found}")

            if vector_results:
                llm_matches = await llm_service.find_best_matches(vc_profile, vector_results, top_k=3)
                founder_in_top = any(m['telegram_id'] == ai_founder['user']['telegram_id'] for m in llm_matches)
                print(f"  {'‚úÖ' if founder_in_top else '‚ùå'} AI Founder in LLM top matches: {founder_in_top}")

        # Final statistics
        print(f"\nüìä Final Chunking Test Statistics:")
        print(f"  üë• Total long profiles created: {len(created_users)}")

        total_chunks = sum(len(u['processed_data']['chunks']) for u in created_users)
        avg_chunks = total_chunks / len(created_users) if created_users else 0
        print(f"  üß© Total chunks created: {total_chunks}")
        print(f"  üìà Average chunks per profile: {avg_chunks:.1f}")

        total_length = sum(u['processed_data']['total_length'] for u in created_users)
        avg_length = total_length / len(created_users) if created_users else 0
        print(f"  üìù Average profile length: {avg_length:.0f} chars")

        # Get collection info
        final_info = vector_db.get_collection_info()
        print(f"  üîç Qdrant profiles: {final_info.get('points_count', 0)}")

        print(f"\nüéâ Chunking system test completed successfully!")
        print(f"\nKey findings:")
        print(f"  ‚úÖ Long texts are properly chunked")
        print(f"  ‚úÖ Embeddings are averaged across chunks")
        print(f"  ‚úÖ Vector search works with chunked profiles")
        print(f"  ‚úÖ LLM matching provides relevant results")

        return True

    except Exception as e:
        print(f"‚ùå Chunking test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        try:
            await db.close()
        except:
            pass


if __name__ == "__main__":
    asyncio.run(test_chunking_system())