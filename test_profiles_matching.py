#!/usr/bin/env python3
"""
Comprehensive test for profile creation and matching system
"""

import asyncio
import os
import sys
from dotenv import load_dotenv

# Add current directory to path
sys.path.insert(0, os.path.dirname(__file__))

# Load environment variables
load_dotenv()


async def test_comprehensive_system():
    """Test complete profile creation and matching system"""
    print("üöÄ Testing Comprehensive Profile & Matching System\n")

    try:
        # Import modules
        from src.database import db
        from src.embeddings import embedding_service
        from src.vector_db import vector_db
        from src.text_processing import text_processor
        from src.llm_service import llm_service

        # Initialize systems
        print("üîç Initializing systems...")
        await db.connect()
        await vector_db.initialize()
        embedding_service.load_model()
        print("‚úÖ All systems initialized")

        # Clear existing test data
        print("\nüßπ Cleaning up existing test data...")
        try:
            # Clean SQLite
            import aiosqlite
            async with aiosqlite.connect(db.db_path) as conn:
                # Delete profiles first (due to foreign key constraints)
                await conn.execute("""
                    DELETE FROM user_profiles WHERE user_id IN (
                        SELECT id FROM users WHERE telegram_id BETWEEN 10000 AND 19999
                    )
                """)
                await conn.execute("""
                    DELETE FROM profile_history WHERE user_id IN (
                        SELECT id FROM users WHERE telegram_id BETWEEN 10000 AND 19999
                    )
                """)
                await conn.execute("""
                    DELETE FROM user_states WHERE user_id IN (
                        SELECT id FROM users WHERE telegram_id BETWEEN 10000 AND 19999
                    )
                """)
                # Now delete users
                await conn.execute("DELETE FROM users WHERE telegram_id BETWEEN 10000 AND 19999")
                await conn.commit()

            # Clean Qdrant (delete points with IDs we'll use)
            for user_id in range(1, 20):  # Wider range for cleanup
                try:
                    vector_db.delete_profile(user_id)
                except:
                    pass

            print("‚úÖ Test data cleaned")
        except Exception as e:
            print(f"‚ö†Ô∏è Cleanup warning: {e}")

        # Create diverse test profiles
        test_profiles = [
            {
                "telegram_id": 10001,
                "username": "dev_alex",
                "first_name": "–ê–ª–µ–∫—Å–∞–Ω–¥—Ä",
                "last_name": "–†–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫",
                "answers": [
                    "–Ø Senior Python —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫, —Ä–∞–±–æ—Ç–∞—é —Å Django, FastAPI –∏ –º–∞—à–∏–Ω–Ω—ã–º –æ–±—É—á–µ–Ω–∏–µ–º. –ò–º–µ—é –æ–ø—ã—Ç —Å–æ–∑–¥–∞–Ω–∏—è –≤—ã—Å–æ–∫–æ–Ω–∞–≥—Ä—É–∂–µ–Ω–Ω—ã—Ö –≤–µ–±-—Å–µ—Ä–≤–∏—Å–æ–≤",
                    "–ò—â—É —Ç–µ—Ö–Ω–∏—á–µ—Å–∫–æ–µ –ø–∞—Ä—Ç–Ω–µ—Ä—Å—Ç–≤–æ –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è AI-—Å—Ç–∞—Ä—Ç–∞–ø–∞, –Ω—É–∂–Ω—ã –∏–Ω–≤–µ—Å—Ç–æ—Ä—ã –∏ –±–∏–∑–Ω–µ—Å-–ø–∞—Ä—Ç–Ω–µ—Ä—ã",
                    "–ú–æ–≥—É –ø–æ–º–æ—á—å —Å –∞—Ä—Ö–∏—Ç–µ–∫—Ç—É—Ä–æ–π —Å–∏—Å—Ç–µ–º—ã, —Ä–∞–∑—Ä–∞–±–æ—Ç–∫–æ–π MVP, –Ω–∞—Å—Ç—Ä–æ–π–∫–æ–π CI/CD –∏ –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ–º junior —Ä–∞–∑—Ä–∞–±–æ—Ç—á–∏–∫–æ–≤"
                ]
            },
            {
                "telegram_id": 10002,
                "username": "investor_maria",
                "first_name": "–ú–∞—Ä–∏—è",
                "last_name": "–ò–Ω–≤–µ—Å—Ç–æ—Ä",
                "answers": [
                    "–Ø –≤–µ–Ω—á—É—Ä–Ω—ã–π –∏–Ω–≤–µ—Å—Ç–æ—Ä, —Å–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ IT-—Å—Ç–∞—Ä—Ç–∞–ø–∞—Ö –Ω–∞ —Å—Ç–∞–¥–∏–∏ seed –∏ Series A. –ü–æ—Ä—Ç—Ñ–µ–ª—å 50+ –∫–æ–º–ø–∞–Ω–∏–π",
                    "–ò—â—É –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω—ã–µ —Ç–µ—Ö–Ω–æ–ª–æ–≥–∏—á–µ—Å–∫–∏–µ –ø—Ä–æ–µ–∫—Ç—ã –≤ –æ–±–ª–∞—Å—Ç–∏ AI, fintech –∏ healthtech –¥–ª—è –∏–Ω–≤–µ—Å—Ç–∏—Ü–∏–π",
                    "–ü—Ä–µ–¥–æ—Å—Ç–∞–≤–ª—è—é —Ñ–∏–Ω–∞–Ω—Å–∏—Ä–æ–≤–∞–Ω–∏–µ –æ—Ç $100K –¥–æ $5M, –º–µ–Ω—Ç–æ—Ä—Å—Ç–≤–æ, —Å–≤—è–∑–∏ —Å –∫–ª–∏–µ–Ω—Ç–∞–º–∏ –∏ —ç–∫—Å–ø–µ—Ä—Ç–∏–∑—É –ø–æ –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—é"
                ]
            },
            {
                "telegram_id": 10003,
                "username": "designer_kate",
                "first_name": "–ï–∫–∞—Ç–µ—Ä–∏–Ω–∞",
                "last_name": "–î–∏–∑–∞–π–Ω–µ—Ä",
                "answers": [
                    "UX/UI –¥–∏–∑–∞–π–Ω–µ—Ä —Å 7-–ª–µ—Ç–Ω–∏–º –æ–ø—ã—Ç–æ–º, —Ä–∞–±–æ—Ç–∞–ª–∞ –≤ –Ø–Ω–¥–µ–∫—Å–µ –∏ Mail.ru. –°–ø–µ—Ü–∏–∞–ª–∏–∑–∏—Ä—É—é—Å—å –Ω–∞ –º–æ–±–∏–ª—å–Ω—ã—Ö –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è—Ö",
                    "–ò—â—É –∫–æ–º–∞–Ω–¥—É –¥–ª—è —Å–æ–∑–¥–∞–Ω–∏—è –∏–Ω–Ω–æ–≤–∞—Ü–∏–æ–Ω–Ω–æ–≥–æ –ø—Ä–æ–¥—É–∫—Ç–∞, —Ö–æ—á—É —Å—Ç–∞—Ç—å co-founder –≤ –ø–µ—Ä—Å–ø–µ–∫—Ç–∏–≤–Ω–æ–º —Å—Ç–∞—Ä—Ç–∞–ø–µ",
                    "–ú–æ–≥—É —Å–æ–∑–¥–∞—Ç—å –ø–æ–ª–Ω—ã–π –¥–∏–∑–∞–π–Ω –ø—Ä–æ–¥—É–∫—Ç–∞ –æ—Ç –∏—Å—Å–ª–µ–¥–æ–≤–∞–Ω–∏–π –¥–æ –≥–æ—Ç–æ–≤—ã—Ö –º–∞–∫–µ—Ç–æ–≤, –ø—Ä–æ–≤–µ—Å—Ç–∏ UX-–∞—É–¥–∏—Ç –∏ A/B —Ç–µ—Å—Ç—ã"
                ]
            },
            {
                "telegram_id": 10004,
                "username": "marketer_john",
                "first_name": "–ò–≤–∞–Ω",
                "last_name": "–ú–∞—Ä–∫–µ—Ç–æ–ª–æ–≥",
                "answers": [
                    "Digital-–º–∞—Ä–∫–µ—Ç–æ–ª–æ–≥, —ç–∫—Å–ø–µ—Ä—Ç –ø–æ performance-–º–∞—Ä–∫–µ—Ç–∏–Ω–≥—É. –ó–∞–ø—É—Å–∫–∞–ª —Ä–µ–∫–ª–∞–º—É —Å –±—é–¥–∂–µ—Ç–æ–º $1M+",
                    "–ò—â—É —Å—Ç–∞—Ä—Ç–∞–ø—ã –Ω–∞ —Å—Ç–∞–¥–∏–∏ product-market fit –¥–ª—è –º–∞—Å—à—Ç–∞–±–∏—Ä–æ–≤–∞–Ω–∏—è —á–µ—Ä–µ–∑ –ø–ª–∞—Ç–Ω—ã–µ –∫–∞–Ω–∞–ª—ã",
                    "–ü–æ–º–æ–≥—É –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å –≤–æ—Ä–æ–Ω–∫–∏ –ø—Ä–æ–¥–∞–∂, –∑–∞–ø—É—Å—Ç–∏—Ç—å —Ä–µ–∫–ª–∞–º—É –≤ Facebook/Google, –ø—Ä–æ–≤–µ—Å—Ç–∏ CRO –∏ —É–≤–µ–ª–∏—á–∏—Ç—å LTV"
                ]
            },
            {
                "telegram_id": 10005,
                "username": "sales_director",
                "first_name": "–î–º–∏—Ç—Ä–∏–π",
                "last_name": "–ü—Ä–æ–¥–∞–∂–Ω–∏–∫",
                "answers": [
                    "–î–∏—Ä–µ–∫—Ç–æ—Ä –ø–æ –ø—Ä–æ–¥–∞–∂–∞–º B2B, 10 –ª–µ—Ç –æ–ø—ã—Ç–∞. –ü–æ—Å—Ç—Ä–æ–∏–ª –æ—Ç–¥–µ–ª—ã –ø—Ä–æ–¥–∞–∂ –≤ 3 –∫–æ–º–ø–∞–Ω–∏—è—Ö –æ—Ç 0 –¥–æ $10M ARR",
                    "–ò—â—É –ø–æ–∑–∏—Ü–∏—é CPO –∏–ª–∏ co-founder –≤ B2B SaaS —Å—Ç–∞—Ä—Ç–∞–ø–µ —Å –≥–æ—Ç–æ–≤—ã–º –ø—Ä–æ–¥—É–∫—Ç–æ–º",
                    "–ú–æ–≥—É –ø–æ—Å—Ç—Ä–æ–∏—Ç—å –æ—Ç–¥–µ–ª –ø—Ä–æ–¥–∞–∂ —Å –Ω—É–ª—è, –æ–±—É—á–∏—Ç—å –∫–æ–º–∞–Ω–¥—É, –Ω–∞—Å—Ç—Ä–æ–∏—Ç—å CRM –∏ –ø—Ä–æ—Ü–µ—Å—Å—ã, –Ω–∞–π—Ç–∏ –ø–µ—Ä–≤—ã—Ö –∫–ª–∏–µ–Ω—Ç–æ–≤"
                ]
            },
            {
                "telegram_id": 10006,
                "username": "data_scientist",
                "first_name": "–ê–Ω–Ω–∞",
                "last_name": "–ê–Ω–∞–ª–∏—Ç–∏–∫",
                "answers": [
                    "Data Scientist, PhD –≤ –æ–±–ª–∞—Å—Ç–∏ –º–∞—à–∏–Ω–Ω–æ–≥–æ –æ–±—É—á–µ–Ω–∏—è. –†–∞–±–æ—Ç–∞—é —Å NLP, computer vision –∏ —Ä–µ–∫–æ–º–µ–Ω–¥–∞—Ç–µ–ª—å–Ω—ã–º–∏ —Å–∏—Å—Ç–µ–º–∞–º–∏",
                    "–ò—â—É –ø—Ä–æ–µ–∫—Ç—ã –≤ –æ–±–ª–∞—Å—Ç–∏ AI/ML, —Ö–æ—á—É –ø—Ä–∏–º–µ–Ω–∏—Ç—å —Å–≤–æ–∏ –∑–Ω–∞–Ω–∏—è –≤ –∫–æ–º–º–µ—Ä—á–µ—Å–∫–∏—Ö –ø—Ä–æ–¥—É–∫—Ç–∞—Ö",
                    "–ú–æ–≥—É —Å–æ–∑–¥–∞—Ç—å ML-–º–æ–¥–µ–ª–∏, –ø—Ä–æ–≤–µ—Å—Ç–∏ –∞–Ω–∞–ª–∏–∑ –¥–∞–Ω–Ω—ã—Ö, –ø–æ—Å—Ç—Ä–æ–∏—Ç—å data pipeline –∏ –≤–Ω–µ–¥—Ä–∏—Ç—å AI –≤ –ø—Ä–æ–¥—É–∫—Ç"
                ]
            }
        ]

        created_users = []

        print(f"\nüë• Creating {len(test_profiles)} diverse test profiles...")

        for i, profile_data in enumerate(test_profiles, 1):
            try:
                print(f"\nüîç Creating profile {i}/{len(test_profiles)}: {profile_data['first_name']}")

                # Create user
                user = await db.get_or_create_user(
                    telegram_id=profile_data["telegram_id"],
                    username=profile_data["username"],
                    first_name=profile_data["first_name"],
                    last_name=profile_data["last_name"]
                )

                # Process profile text
                processed_data = text_processor.prepare_profile_text(
                    profile_data["answers"][0],
                    profile_data["answers"][1],
                    profile_data["answers"][2]
                )

                print(f"  üìù Keywords: {processed_data['keywords'][:5]}...")

                # Create embedding
                embedding = embedding_service.create_profile_embedding(
                    processed_data['clean_answers']['answer_1'],
                    processed_data['clean_answers']['answer_2'],
                    processed_data['clean_answers']['answer_3']
                )

                # Save to SQLite
                await db.save_user_profile(
                    user['id'],
                    processed_data['clean_answers']['answer_1'],
                    processed_data['clean_answers']['answer_2'],
                    processed_data['clean_answers']['answer_3'],
                    embedding,
                    processed_data['keywords']
                )

                # Save to Qdrant
                profile_payload = {
                    "telegram_id": user['telegram_id'],
                    "username": user['username'],
                    "first_name": user['first_name'],
                    "last_name": user['last_name'],
                    "answer_1": processed_data['clean_answers']['answer_1'],
                    "answer_2": processed_data['clean_answers']['answer_2'],
                    "answer_3": processed_data['clean_answers']['answer_3'],
                    "keywords": processed_data['keywords']
                }

                vector_db.save_profile_embedding(user['id'], embedding, profile_payload)

                created_users.append({
                    'user': user,
                    'profile_data': profile_data,
                    'processed_data': processed_data,
                    'embedding': embedding
                })

                print(f"  ‚úÖ Profile created and saved")

            except Exception as e:
                print(f"  ‚ùå Failed to create profile for {profile_data['first_name']}: {e}")

        print(f"\n‚úÖ Created {len(created_users)} profiles successfully")

        # Get collection info
        info = vector_db.get_collection_info()
        print(f"üìä Qdrant collection: {info['points_count']} profiles stored")

        # Test matching for each user
        print(f"\nüîç Testing matching system for each user...")

        for i, user_data in enumerate(created_users, 1):
            user = user_data['user']
            profile_data = user_data['profile_data']

            print(f"\n--- Matching Test {i}/{len(created_users)}: {profile_data['first_name']} ---")
            print(f"üë§ –ü–æ–ª–Ω—ã–π –ø—Ä–æ—Ñ–∏–ª—å:")
            print(f"   üè¢ –°—Ñ–µ—Ä–∞: {profile_data['answers'][0]}")
            print(f"   üîç –ò—â–µ—Ç: {profile_data['answers'][1]}")
            print(f"   ü§ù –ú–æ–∂–µ—Ç –ø–æ–º–æ—á—å: {profile_data['answers'][2]}")
            print(f"   üìã –ö–ª—é—á–µ–≤—ã–µ —Å–ª–æ–≤–∞: {user_data['processed_data']['keywords'][:5]}")

            try:
                # Get user profile from database
                db_profile = await db.get_user_profile(user['id'])
                if not db_profile:
                    print("  ‚ùå Profile not found in database")
                    continue

                # Test keyword-based search
                keywords = db_profile.get('keywords', [])
                if keywords:
                    keyword_profiles = await db.find_profiles_with_keywords(
                        user['id'], keywords, limit=10
                    )
                    print(f"  üîç Keyword search: found {len(keyword_profiles)} profiles")
                else:
                    keyword_profiles = []

                # Test vector search
                vector_profiles = vector_db.search_similar_profiles(
                    user_data['embedding'], user['id'], limit=10
                )
                print(f"  üîç Vector search: found {len(vector_profiles)} profiles")

                # Combine results
                all_candidates = []
                seen_users = set()

                # Add keyword results
                for p in keyword_profiles:
                    user_key = p['telegram_id']
                    if user_key not in seen_users:
                        seen_users.add(user_key)
                        all_candidates.append(p)

                # Add vector results
                for p in vector_profiles:
                    user_key = p['telegram_id']
                    if user_key not in seen_users:
                        seen_users.add(user_key)
                        all_candidates.append(p)

                print(f"  üìä Total candidates: {len(all_candidates)}")

                if all_candidates:
                    # Test LLM matching
                    try:
                        best_matches = await llm_service.find_best_matches(
                            db_profile, all_candidates, top_k=3
                        )
                        print(f"  ü§ñ LLM analysis: {len(best_matches)} best matches")

                        for j, match in enumerate(best_matches, 1):
                            name = match.get('first_name', 'Unknown')
                            score = match.get('match_score', 'N/A')
                            reason = match.get('match_reason', 'No reason')[:50]
                            print(f"    {j}. {name} (Score: {score}) - {reason}...")

                        # Test summary generation
                        if best_matches:
                            summary = await llm_service.generate_match_summary(db_profile, best_matches)
                            print(f"  üìù Summary: {summary[:80]}...")

                    except Exception as e:
                        print(f"  ‚ö†Ô∏è LLM matching failed: {e}")
                else:
                    print("  ‚ö†Ô∏è No candidates found for matching")

            except Exception as e:
                print(f"  ‚ùå Matching failed: {e}")

        # Test cross-matching scenarios
        print(f"\nüéØ Testing specific matching scenarios...")

        # Scenario 1: Developer looking for investor
        dev_user = next((u for u in created_users if 'dev_alex' in u['user']['username']), None)
        investor_user = next((u for u in created_users if 'investor_maria' in u['user']['username']), None)

        if dev_user and investor_user:
            print(f"\nüìã Scenario 1: Developer ‚Üí Investor matching")
            dev_profile = await db.get_user_profile(dev_user['user']['id'])

            # Search for investor
            vector_results = vector_db.search_similar_profiles(
                dev_user['embedding'], dev_user['user']['id'], limit=5
            )

            investor_found = any(p['telegram_id'] == investor_user['user']['telegram_id'] for p in vector_results)
            print(f"  {'‚úÖ' if investor_found else '‚ùå'} Investor found in vector search: {investor_found}")

            if vector_results:
                llm_matches = await llm_service.find_best_matches(dev_profile, vector_results, top_k=3)
                investor_in_top = any(m['telegram_id'] == investor_user['user']['telegram_id'] for m in llm_matches)
                print(f"  {'‚úÖ' if investor_in_top else '‚ùå'} Investor in LLM top matches: {investor_in_top}")

        # Final statistics
        print(f"\nüìä Final Statistics:")
        print(f"  üë• Total profiles created: {len(created_users)}")
        print(f"  üóÑÔ∏è SQLite profiles: {len(created_users)}")

        final_info = vector_db.get_collection_info()
        print(f"  üîç Qdrant profiles: {final_info.get('points_count', 0)}")
        print(f"  üìà Collection status: {final_info.get('status', 'Unknown')}")

        print(f"\nüéâ Comprehensive test completed successfully!")
        print(f"\nSystem is fully tested and ready for production!")
        print(f"\nTo start the bot: python main.py")

        return True

    except Exception as e:
        print(f"‚ùå Comprehensive test failed: {e}")
        import traceback
        traceback.print_exc()
        return False
    finally:
        try:
            await db.close()
        except:
            pass


if __name__ == "__main__":
    asyncio.run(test_comprehensive_system())